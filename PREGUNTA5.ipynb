{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPeGTWXCBmsvl8CknO3iOjz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/Drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfdSVycLZ4uu","executionInfo":{"status":"ok","timestamp":1728194434038,"user_tz":240,"elapsed":24769,"user":{"displayName":"FIORELA KATHERINE VASQUEZ CONDORI","userId":"04042705054546877418"}},"outputId":"88116822-684d-46b3-b1fb-af7eb3881e4e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/Drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbYn93exZxkn","executionInfo":{"status":"ok","timestamp":1728194487407,"user_tz":240,"elapsed":451,"user":{"displayName":"FIORELA KATHERINE VASQUEZ CONDORI","userId":"04042705054546877418"}},"outputId":"bba8e7d9-7e4a-46af-9316-85074e494ea0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Coeficientes Lasso (L1): [ 2.30096684e-04  1.19037367e-01  1.01106934e-04  6.65825774e-04\n"," -7.02797124e-04  1.29378563e-02  1.24767090e-03  1.83787258e-05]\n","\n","Coeficientes Ridge (L2): [ 0.06283231  0.16992122 -0.03653543  0.00139806 -0.01151291  0.09562498\n","  0.04581601  0.03466618]\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Cargar el dataset de diabetes\n","df = pd.read_csv('/content/Drive/MyDrive/datos/diabetes.csv')\n","\n","# Separar las características (X) y la variable objetivo (y)\n","X = df.drop(columns=['Outcome']).values  # Todas las columnas excepto 'Outcome'\n","y = df['Outcome'].values  # La columna 'Outcome'\n","\n","# Normalización de los datos\n","def normalize(X):\n","    return (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n","\n","X_normalized = normalize(X)\n","\n","# Función de costo para Lasso (L1)\n","def lasso_cost(X, y, beta, alpha):\n","    n = len(y)\n","    predictions = X.dot(beta)\n","    cost = (1 / (2 * n)) * np.sum((predictions - y) ** 2) + alpha * np.sum(np.abs(beta))\n","    return cost\n","\n","# Función de costo para Ridge (L2)\n","def ridge_cost(X, y, beta, alpha):\n","    n = len(y)\n","    predictions = X.dot(beta)\n","    cost = (1 / (2 * n)) * np.sum((predictions - y) ** 2) + (alpha / 2) * np.sum(beta ** 2)\n","    return cost\n","\n","# Gradiente para Lasso\n","def lasso_gradient(X, y, beta, alpha):\n","    n = len(y)\n","    predictions = X.dot(beta)\n","    grad = (1 / n) * X.T.dot(predictions - y) + alpha * np.sign(beta)\n","    return grad\n","\n","# Gradiente para Ridge\n","def ridge_gradient(X, y, beta, alpha):\n","    n = len(y)\n","    predictions = X.dot(beta)\n","    grad = (1 / n) * X.T.dot(predictions - y) + alpha * beta\n","    return grad\n","\n","# Función para entrenar el modelo\n","def train_model(X, y, alpha, penalty_type, num_iterations=1000, learning_rate=0.01):\n","    beta = np.zeros(X.shape[1])\n","    for _ in range(num_iterations):\n","        if penalty_type == 'l1':\n","            beta -= learning_rate * lasso_gradient(X, y, beta, alpha)\n","        elif penalty_type == 'l2':\n","            beta -= learning_rate * ridge_gradient(X, y, beta, alpha)\n","    return beta\n","\n","# Entrenamos el modelo con penalización L1 (Lasso)\n","alpha = 0.1\n","beta_lasso = train_model(X_normalized, y, alpha, 'l1')\n","print(\"Coeficientes Lasso (L1):\", beta_lasso)\n","print(\"\")\n","# Entrenamos el modelo con penalización L2 (Ridge)\n","beta_ridge = train_model(X_normalized, y, alpha, 'l2')\n","print(\"Coeficientes Ridge (L2):\", beta_ridge)\n"]}]}